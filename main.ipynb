{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Lab Four: Multi-Layer Perceptron\n",
    "By Saaketh Koka, Vedant Nilabh, and Rayaan Irani \n",
    "\n",
    "In this lab, we will make a multi-layer perceptron (a type of Neural Network) which takes in data provided by the US Census Bearueau on a county-wide basis to determine the child poverty level in the county. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load, Split, and Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Import statements for the program \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "from sklearn import preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74001 entries, 0 to 74000\n",
      "Data columns (total 37 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   TractId           74001 non-null  int64  \n",
      " 1   State             74001 non-null  int64  \n",
      " 2   County            74001 non-null  int64  \n",
      " 3   TotalPop          74001 non-null  int64  \n",
      " 4   Men               74001 non-null  int64  \n",
      " 5   Women             74001 non-null  int64  \n",
      " 6   Hispanic          73305 non-null  float64\n",
      " 7   White             73305 non-null  float64\n",
      " 8   Black             73305 non-null  float64\n",
      " 9   Native            73305 non-null  float64\n",
      " 10  Asian             73305 non-null  float64\n",
      " 11  Pacific           73305 non-null  float64\n",
      " 12  VotingAgeCitizen  74001 non-null  int64  \n",
      " 13  Income            72885 non-null  float64\n",
      " 14  IncomeErr         72885 non-null  float64\n",
      " 15  IncomePerCap      73256 non-null  float64\n",
      " 16  IncomePerCapErr   73256 non-null  float64\n",
      " 17  Poverty           73159 non-null  float64\n",
      " 18  ChildPoverty      72891 non-null  float64\n",
      " 19  Professional      73190 non-null  float64\n",
      " 20  Service           73190 non-null  float64\n",
      " 21  Office            73190 non-null  float64\n",
      " 22  Construction      73190 non-null  float64\n",
      " 23  Production        73190 non-null  float64\n",
      " 24  Drive             73200 non-null  float64\n",
      " 25  Carpool           73200 non-null  float64\n",
      " 26  Transit           73200 non-null  float64\n",
      " 27  Walk              73200 non-null  float64\n",
      " 28  OtherTransp       73200 non-null  float64\n",
      " 29  WorkAtHome        73200 non-null  float64\n",
      " 30  MeanCommute       73055 non-null  float64\n",
      " 31  Employed          74001 non-null  int64  \n",
      " 32  PrivateWork       73190 non-null  float64\n",
      " 33  PublicWork        73190 non-null  float64\n",
      " 34  SelfEmployed      73190 non-null  float64\n",
      " 35  FamilyWork        73190 non-null  float64\n",
      " 36  Unemployment      73191 non-null  float64\n",
      "dtypes: float64(29), int64(8)\n",
      "memory usage: 20.9 MB\n"
     ]
    }
   ],
   "source": [
    "#Loads in all of the data into a Pandas Data Frame\n",
    "df = pd.read_csv(\"acs2017_census_tract_data.csv\")\n",
    "\n",
    "df.dropna() #Removes rows that have missing values \n",
    "\n",
    "#This converts all of the string values into numerical values\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['State'] = le.fit_transform(df['State'])\n",
    "df['County'] = le.fit_transform(df['County'])\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median number of census tracts per county: 9.0\n",
      "Mean number of census tracts per county: 37.85217391304348\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = list(df[\"County\"].groupby(df[\"County\"]).count())\n",
    "plt.hist(counts, bins = 20)\n",
    "plt.title(\"Number of Census Tracts per County\")\n",
    "plt.xlabel(\"Number of Census Tracts\")\n",
    "plt.ylabel(\"Number of Counties\")\n",
    "\n",
    "#Shows the median number of census tracts per county\n",
    "print(\"Median number of census tracts per county: \" + str(np.median(counts)))\n",
    "\n",
    "#Shows the mean number of census tracts per county\n",
    "print(\"Mean number of census tracts per county: \" + str(np.mean(counts)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counites should be kept as a feature. This is becuase counties like states play a role in funding poverty relief programs. The extent to which these programs are funded is a result of the relative wealth of the county (as most county tax revenue is derived from property taxes). Due to this, it is possible that two census tracks that are very similar in other data types may differ greatly in poverty levels because one is surronded by a richer area and thus gets more county funding and the other does not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discreatizing the Unemployment Variable into 4 classes, 1,2,3,4\n",
    "classes = pd.qcut(df['ChildPoverty'], 4, labels = [1,2,3,4])\n",
    "df['ChildPoverty'] = classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example adapted from https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch12/ch12.ipynb\n",
    "# Original Author: Sebastian Raschka\n",
    "\n",
    "# This is the optional book we use in the course, excellent intuitions and straightforward programming examples\n",
    "# please note, however, that this code has been manipulated to reflect our assumptions and notation.\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "import sys\n",
    "# accuracy score:\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# start with a simple base classifier, which can't be fit or predicted\n",
    "# it only has internal classes to be used by classes that will subclass it\n",
    "class TwoLayerPerceptronBase(object):\n",
    "    def __init__(self, n_hidden=30,\n",
    "                 C=0.0, epochs=500, eta=0.001, random_state=None,\n",
    "                 alpha=0.0, decrease_const=0.0, shuffle=True,\n",
    "                 minibatches=1):\n",
    "        np.random.seed(random_state)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.l2_C = C\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        # From the TLPMiniBatch class\n",
    "        self.alpha = alpha\n",
    "        self.decrease_const = decrease_const\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatches = minibatches\n",
    "        \n",
    "    @staticmethod\n",
    "    def _encode_labels(y):\n",
    "        \"\"\"Encode labels into one-hot representation\"\"\"\n",
    "        onehot = pd.get_dummies(y).values.T\n",
    "            \n",
    "        return onehot\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights Glorot and He normalization.\"\"\"\n",
    "        init_bound = 4*np.sqrt(6. / (self.n_hidden + self.n_features_ + 1))\n",
    "        W1 = np.random.uniform(-init_bound, init_bound,(self.n_hidden, self.n_features_ + 1))\n",
    "        W1[:,:1] = 0\n",
    "        \n",
    "        # reduce the final layer magnitude in order to balance the size of the gradients\n",
    "        # between \n",
    "        init_bound = 4*np.sqrt(6 / (self.n_output_ + self.n_hidden + 1))\n",
    "        W2 = np.random.uniform(-init_bound, init_bound,(self.n_output_, self.n_hidden + 1)) \n",
    "        W2[:,:1] = 0\n",
    "        \n",
    "        return W1, W2\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(z):\n",
    "        \"\"\"Use scipy.special.expit to avoid overflow\"\"\"\n",
    "        # 1.0 / (1.0 + np.exp(-z))\n",
    "        return expit(z)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_bias_unit(X, how='column'):\n",
    "        \"\"\"Add bias unit (column or row of 1s) to array at index 0\"\"\"\n",
    "        if how == 'column':\n",
    "            ones = np.ones((X.shape[0], 1))\n",
    "            X_new = np.hstack((ones, X))\n",
    "        elif how == 'row':\n",
    "            ones = np.ones((1, X.shape[1]))\n",
    "            X_new = np.vstack((ones, X))\n",
    "        return X_new\n",
    "    \n",
    "    @staticmethod\n",
    "    def _L2_reg(lambda_, W1, W2):\n",
    "        \"\"\"Compute L2-regularization cost\"\"\"\n",
    "        # only compute for non-bias terms\n",
    "        return (lambda_/2.0) * np.sqrt(np.mean(W1[:, 1:] ** 2) + np.mean(W2[:, 1:] ** 2))\n",
    "    \n",
    "    # Cross Entropy Cost Function\n",
    "    def _cost(self,A3,Y_enc,W1,W2):\n",
    "        '''Get the objective function value'''\n",
    "        cost = -np.mean(np.nan_to_num((Y_enc*np.log(A3)+(1-Y_enc)*np.log(1-A3))))\n",
    "        L2_term = self._L2_reg(self.l2_C, W1, W2)\n",
    "        return cost + L2_term\n",
    "    \n",
    "    def _feedforward(self, X, W1, W2):\n",
    "        \"\"\"Compute feedforward step\n",
    "        \"\"\"\n",
    "        A1 = self._add_bias_unit(X, how='column')\n",
    "        A1 = A1.T\n",
    "        Z1 = W1 @ A1\n",
    "        A2 = self._sigmoid(Z1)\n",
    "        A2 = self._add_bias_unit(A2, how='row')\n",
    "        Z2 = W2 @ A2\n",
    "        A3 = self._sigmoid(Z2)\n",
    "        return A1, Z1, A2, Z2, A3\n",
    "    \n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # vectorized backpropagation\n",
    "        V2 = (A3-Y_enc) # <- this is only line that changed when switching to cross entropy\n",
    "        V1 = A2*(1-A2)*(W2.T @ V2)\n",
    "        \n",
    "        grad2 = V2 @ A2.T\n",
    "        grad1 = V1[1:,:] @ A1.T\n",
    "        \n",
    "        # regularize weights that are not bias terms\n",
    "        grad1[:, 1:] += W1[:, 1:] * self.l2_C\n",
    "        grad2[:, 1:] += W2[:, 1:] * self.l2_C\n",
    "\n",
    "        return grad1, grad2\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels\"\"\"\n",
    "        _, _, _, _, A3 = self._feedforward(X, self.W1, self.W2)\n",
    "        y_pred = np.argmax(A3, axis=0)\n",
    "        return y_pred\n",
    "\n",
    "    def fit(self, X, y, print_progress=False, XY_test=None):\n",
    "        \"\"\" Learn weights from training data. With mini-batch\"\"\"\n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        Y_enc = self._encode_labels(y)\n",
    "        \n",
    "        # init weights and setup matrices\n",
    "        self.n_features_ = X_data.shape[1]\n",
    "        self.n_output_ = Y_enc.shape[0]\n",
    "        self.W1, self.W2 = self._initialize_weights()\n",
    "\n",
    "        rho_W1_prev = np.zeros(self.W1.shape)\n",
    "        rho_W2_prev = np.zeros(self.W2.shape)\n",
    "\n",
    "        self.cost_ = []\n",
    "        self.score_ = []\n",
    "        # get starting acc\n",
    "        self.score_.append(accuracy_score(y_data,self.predict(X_data)))\n",
    "        # keep track of validation, if given\n",
    "        if XY_test is not None:\n",
    "            X_test = XY_test[0].copy()\n",
    "            y_test = XY_test[1].copy()\n",
    "            self.val_score_ = []\n",
    "            self.val_score_.append(accuracy_score(y_test,self.predict(X_test)))\n",
    "            \n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            # adaptive learning rate\n",
    "            # \\frac{\\eta}{1+\\epsilon\\cdot k}\n",
    "            eta = self.eta / (1 + self.decrease_const*i)\n",
    "\n",
    "            if print_progress>0 and (i+1)%print_progress==0:\n",
    "                sys.stderr.write('\\rEpoch: %d/%d' % (i+1, self.epochs))\n",
    "                sys.stderr.flush()\n",
    "\n",
    "            if self.shuffle:\n",
    "                idx_shuffle = np.random.permutation(y_data.shape[0])\n",
    "                X_data, Y_enc, y_data = X_data[idx_shuffle], Y_enc[:, idx_shuffle], y_data[idx_shuffle]\n",
    "\n",
    "            mini = np.array_split(range(y_data.shape[0]), self.minibatches)\n",
    "            mini_cost = []\n",
    "            for idx in mini:\n",
    "\n",
    "                # feedforward\n",
    "                A1, Z1, A2, Z2, A3 = self._feedforward(X_data[idx],\n",
    "                                                       self.W1,\n",
    "                                                       self.W2)\n",
    "                \n",
    "                cost = self._cost(A3,Y_enc[:, idx],self.W1,self.W2)\n",
    "                mini_cost.append(cost) # this appends cost of mini-batch only\n",
    "\n",
    "                # compute gradient via backpropagation\n",
    "                grad1, grad2 = self._get_gradient(A1=A1, A2=A2, A3=A3, Z1=Z1, Z2=Z2, \n",
    "                                                  Y_enc=Y_enc[:, idx],\n",
    "                                                  W1=self.W1,W2=self.W2)\n",
    "\n",
    "                # momentum calculations\n",
    "                rho_W1, rho_W2 = eta * grad1, eta * grad2\n",
    "                self.W1 -= (rho_W1 + (self.alpha * rho_W1_prev))\n",
    "                self.W2 -= (rho_W2 + (self.alpha * rho_W2_prev))\n",
    "                rho_W1_prev, rho_W2_prev = rho_W1, rho_W2\n",
    "\n",
    "            self.cost_.append(mini_cost)\n",
    "            self.score_.append(accuracy_score(y_data,self.predict(X_data)))\n",
    "            if XY_test is not None:\n",
    "                self.val_score_.append(accuracy_score(y_test,self.predict(X_test)))\n",
    "            \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Exceptional Work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "25e4221c4bfc6613b6992afadb06314c1c773e6812ad1816013b8a7c9f96b882"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
